{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0QOigux19rKH"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import os\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 165,
      "metadata": {
        "id": "yIcx0QqXGh_0"
      },
      "outputs": [],
      "source": [
        "# === Functions ===\n",
        "def preprocess(image, label):\n",
        "    normalized_img = tf.cast(image, tf.float32) / 255.0\n",
        "\n",
        "    return normalized_img, label\n",
        "\n",
        "def load_and_preprocess(file_path, label):\n",
        "     # Read file\n",
        "    img = tf.io.read_file(file_path)\n",
        "    # Decode JPEG (or PNG)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    #resize\n",
        "    img = tf.image.resize(img, [256, 256])\n",
        "    return preprocess(img, label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "obXpoxngEFOU",
        "outputId": "5f7a64b7-732c-40d6-d4a6-2d34001a1047"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total images: 3087\n"
          ]
        }
      ],
      "source": [
        "DATADIR = r\"C:\\Users\\PAULA\\OneDrive\\Desktop\\computer vision\\Teeth DataSet\\Teeth_Dataset\\Training\"\n",
        "CATEGORIES = [\"CaS\", \"CoS\", \"Gum\", \"MC\", \"OC\", \"OLP\", \"OT\"]\n",
        "\n",
        "train_file_paths = []\n",
        "train_labels = []\n",
        "\n",
        "for category in CATEGORIES:\n",
        "    path = os.path.join(DATADIR, category)\n",
        "    label = CATEGORIES.index(category)\n",
        "    for img in os.listdir(path):\n",
        "        train_file_paths.append(os.path.join(path, img))\n",
        "        train_labels.append(label)\n",
        "\n",
        "print(\"Total images:\", len(train_file_paths))\n",
        "train_data = tf.data.Dataset.from_tensor_slices((train_file_paths, train_labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 167,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GNaDs4vLFw-l",
        "outputId": "fdd67fac-a8a8-476d-bc60-4f377f04d232"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total images: 1028\n"
          ]
        }
      ],
      "source": [
        "DATADIR = r\"C:\\Users\\PAULA\\OneDrive\\Desktop\\computer vision\\Teeth DataSet\\Teeth_Dataset\\Testing\"\n",
        "CATEGORIES = [\"CaS\", \"CoS\", \"Gum\", \"MC\", \"OC\", \"OLP\", \"OT\"]\n",
        "\n",
        "test_file_paths = []\n",
        "test_labels = []\n",
        "\n",
        "for category in CATEGORIES:\n",
        "    path = os.path.join(DATADIR, category)\n",
        "    label = CATEGORIES.index(category)\n",
        "    for img in os.listdir(path):\n",
        "        test_file_paths.append(os.path.join(path, img))\n",
        "        test_labels.append(label)\n",
        "\n",
        "print(\"Total images:\", len(test_file_paths))\n",
        "test_data = tf.data.Dataset.from_tensor_slices((test_file_paths, test_labels))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 168,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZf6RGhPGGY7",
        "outputId": "00af40e3-59bf-4a98-af49-98674d009653"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total images: 1028\n"
          ]
        }
      ],
      "source": [
        "DATADIR = r\"C:\\Users\\PAULA\\OneDrive\\Desktop\\computer vision\\Teeth DataSet\\Teeth_Dataset\\Validation\"\n",
        "CATEGORIES = [\"CaS\", \"CoS\", \"Gum\", \"MC\", \"OC\", \"OLP\", \"OT\"]\n",
        "\n",
        "val_file_paths = []\n",
        "val_labels = []\n",
        "\n",
        "for category in CATEGORIES:\n",
        "    path = os.path.join(DATADIR, category)\n",
        "    label = CATEGORIES.index(category)\n",
        "    for img in os.listdir(path):\n",
        "        val_file_paths.append(os.path.join(path, img))\n",
        "        val_labels.append(label)\n",
        "\n",
        "print(\"Total images:\", len(val_file_paths))\n",
        "val_data = tf.data.Dataset.from_tensor_slices((val_file_paths, val_labels))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 169,
      "metadata": {
        "id": "_4F6sJ7uGyJb"
      },
      "outputs": [],
      "source": [
        "def train_data_prep(data,shuffle_size,batch_size):\n",
        "  dataset = train_data.map(load_and_preprocess)\n",
        "  dataset=dataset.cache()\n",
        "  dataset=dataset.shuffle(shuffle_size).repeat()\n",
        "  dataset=dataset.batch(batch_size)\n",
        "  dataset.prefetch(1)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 170,
      "metadata": {
        "id": "eZRxQYUPHFW3"
      },
      "outputs": [],
      "source": [
        "def test_data_prep(data,batch_size):\n",
        "  dataset = test_data.map(load_and_preprocess)\n",
        "  dataset=dataset.cache()\n",
        "  dataset=dataset.batch(batch_size)\n",
        "  dataset.prefetch(1)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 171,
      "metadata": {
        "id": "UCBSJAmzI2as"
      },
      "outputs": [],
      "source": [
        "def test_data_prep(data,batch_size):\n",
        "  dataset = val_data.map(load_and_preprocess)\n",
        "  dataset=dataset.cache()\n",
        "  dataset=dataset.batch(batch_size)\n",
        "  dataset.prefetch(1)\n",
        "  return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 172,
      "metadata": {
        "id": "41aFDPI3H3Gm"
      },
      "outputs": [],
      "source": [
        "train=train_data_prep(train_data,shuffle_size=300,batch_size=64)\n",
        "test=test_data_prep(test_data,batch_size=64)\n",
        "val=test_data_prep(val_data,batch_size=64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 173,
      "metadata": {
        "id": "bah43p4Tnl55"
      },
      "outputs": [],
      "source": [
        "#DATADIR =\"/content/drive/MyDrive/computer vision /Teeth_Dataset/Training\"  # your root folder\n",
        "#CATEGORIES = [\"CaS\",\"CoS\",\"Gum\",\"MC\",\"OC\",\"OLP\",\"OT\"]        # subfolders = classes\n",
        "\n",
        "#for category in CATEGORIES:\n",
        " #   path = os.path.join(DATADIR, category)\n",
        "  #  for img in os.listdir(path):\n",
        "   #     train_data = cv2.imread(os.path.join(path, img))\n",
        "    #    train_data = tf.convert_to_tensor(train_data) # Convert to Tensor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 174,
      "metadata": {
        "id": "4fldobwT49pP"
      },
      "outputs": [],
      "source": [
        "#DATADIR =\"/content/drive/MyDrive/computer vision /Teeth_Dataset/Training\"  # your root folder\n",
        "#CATEGORIES = [\"CaS\",\"CoS\",\"Gum\",\"MC\",\"OC\",\"OLP\",\"OT\"]        # subfolders = classes\n",
        "\n",
        "#for category in CATEGORIES:\n",
        " #   path = os.path.join(DATADIR, category)\n",
        "  #  for img in os.listdir(path):\n",
        "   #     train_data = cv2.imread(os.path.join(path, img))\n",
        "    #    plt.imshow(train_data)\n",
        "     #   plt.title(category)\n",
        "      #  plt.show()\n",
        "    #break\n",
        "    #break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 175,
      "metadata": {
        "id": "JIBPQ2052Qrt"
      },
      "outputs": [],
      "source": [
        "#print(train_data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {
        "id": "7uDi4d-l1i7N"
      },
      "outputs": [],
      "source": [
        "#DATADIR =\"/content/drive/MyDrive/computer vision /Teeth_Dataset/Testing\"  # your root folder\n",
        "#CATEGORIES = [\"CaS\",\"CoS\",\"Gum\",\"MC\",\"OC\",\"OLP\",\"OT\"]        # subfolders = classes\n",
        "\n",
        "#for category in CATEGORIES:\n",
        " #   path = os.path.join(DATADIR, category)\n",
        "  #  for img in os.listdir(path):\n",
        "   #     test_data = cv2.imread(os.path.join(path, img))\n",
        "    #    test_data = tf.convert_to_tensor(test_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "ypQw72M72X5U"
      },
      "outputs": [],
      "source": [
        "#print(test_data.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "tntlSwlk1588"
      },
      "outputs": [],
      "source": [
        "#DATADIR =\"/content/drive/MyDrive/computer vision /Teeth_Dataset/Validation\"  # your root folder\n",
        "#CATEGORIES = [\"CaS\",\"CoS\",\"Gum\",\"MC\",\"OC\",\"OLP\",\"OT\"]        # subfolders = classes\n",
        "\n",
        "#for category in CATEGORIES:\n",
        " #   path = os.path.join(DATADIR, category)\n",
        "    #for img in os.listdir(path):\n",
        "     #   val_data = cv2.imread(os.path.join(path, img))\n",
        "      #  val_data = tf.convert_to_tensor(val_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "hKJgZEQ126-S"
      },
      "outputs": [],
      "source": [
        "#print(val_data.shape())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 180,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hwZAZPkSU13L",
        "outputId": "8b7b1ecb-6aa1-436d-ed72-e8ee781ab7d3"
      },
      "outputs": [],
      "source": [
        "input_shape=(256,256,3)         #####\n",
        "cnn_model=tf.keras.models.Sequential([\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=32,kernel_size=(3,3),activation='relu',input_shape=input_shape),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "    tf.keras.layers.Conv2D(filters=64,kernel_size=(3,3),activation='relu',input_shape=input_shape),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=128,kernel_size=(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=256,kernel_size=(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "\n",
        "    tf.keras.layers.Conv2D(filters=512,kernel_size=(3,3),activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
        "\n",
        "    tf.keras.layers.Flatten(),\n",
        "    \n",
        "    tf.keras.layers.Dense(units=256,activation='relu'),\n",
        "   \n",
        "    tf.keras.layers.Dense(units=128,activation='relu'),\n",
        "    \n",
        "    tf.keras.layers.Dense(units=7,activation='softmax')\n",
        "\n",
        "])  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 181,
      "metadata": {
        "id": "wIq2U0kk-56T"
      },
      "outputs": [],
      "source": [
        "cnn_model.compile(optimizer='nadam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sNjrKDBQ_N60",
        "outputId": "090c55bd-b747-4f31-f53f-82ffece004b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 2s/step - accuracy: 0.5579 - loss: 1.3784 - val_accuracy: 0.1240 - val_loss: 4.0786\n",
            "Epoch 2/5\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 2s/step - accuracy: 0.2643 - loss: 1.7838 - val_accuracy: 0.1240 - val_loss: 2.6047\n",
            "Epoch 3/5\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.3553 - loss: 1.5203 - val_accuracy: 0.1240 - val_loss: 4.0234\n",
            "Epoch 4/5\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.3994 - loss: 1.4560 - val_accuracy: 0.1240 - val_loss: 2.9084\n",
            "Epoch 5/5\n",
            "\u001b[1m48/48\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 2s/step - accuracy: 0.4289 - loss: 1.3989 - val_accuracy: 0.1240 - val_loss: 2.5589\n"
          ]
        }
      ],
      "source": [
        "batch_size=64\n",
        "train_steps=len(train_file_paths)//64\n",
        "val_steps=len(val_file_paths)//64\n",
        "\n",
        "model_history=cnn_model.fit(train,epochs=5,validation_data=val,steps_per_epoch=train_steps,validation_steps=val_steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {
        "id": "HAp6CDcRa9Aq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 453ms/step - accuracy: 0.0247 - loss: 2.5963\n",
            "Test loss: 2.5513088703155518\n",
            "Test accuracy: 0.12743189930915833\n"
          ]
        }
      ],
      "source": [
        "test_loss, test_acc = cnn_model.evaluate(test)\n",
        "print(\"Test loss:\", test_loss)\n",
        "print(\"Test accuracy:\", test_acc)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
